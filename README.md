# LoRA Web Builder: On-Demand Persona Adapters for Llama-3

A novel implementation of Text-to-LoRA (T2L) hypernetworks for controllable personality steering in large language models, demonstrating how weight-space linearity extends beyond task competence to dynamic style adaptation.

## ğŸ¯ Project Overview

This project leverages the Text-to-LoRA (T2L) hypernetwork architectureÂ¹ to create an end-to-end system that transforms open-domain conversation data into on-demand persona adapters for Llama-3 8B. Rather than focusing on task competence as in the original T2L work, this implementation demonstrates how hypernetworks can enable lightweight, client-side personality and safety steering through controllable style adaptation.

**Key Innovation**: Extending T2L's weight-space linearity principle from task-specific competence to personality trait control, enabling real-time persona switching without model retraining.

## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     T2L PERSONA ADAPTER PIPELINE                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  ğŸ“Š DATASET PREPARATION                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Multi-Source Datasets (84,653 utterances)                          â”‚   â”‚
â”‚  â”‚ â€¢ EmpatheticDialogues â€¢ DailyDialog â€¢ EmotionLines                â”‚   â”‚
â”‚  â”‚ â€¢ MELD â€¢ IEMOCAP                                                   â”‚   â”‚
â”‚  â”‚                              â†“                                     â”‚   â”‚
â”‚  â”‚ Personality Trait Labeling (10 slider-style traits)               â”‚   â”‚
â”‚  â”‚ â€¢ Intellect Â± â€¢ Neuroticism Â± â€¢ Extraversion Â± ...                â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                  â”‚                                          â”‚
â”‚                                  â–¼                                          â”‚
â”‚  ğŸ¤– SYNTHETIC AUGMENTATION                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ GPT-4o Seed Rephrasing                                             â”‚   â”‚
â”‚  â”‚ Neutral utterances â†’ Target personality traits                     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                  â”‚                                          â”‚
â”‚                                  â–¼                                          â”‚
â”‚  ğŸ”§ LORA TRAINING                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ 18 Trait-Specific LoRA Adapters                                    â”‚   â”‚
â”‚  â”‚ Llama-3 8B base model fine-tuning                                  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                  â”‚                                          â”‚
â”‚                                  â–¼                                          â”‚
â”‚  ğŸ§  T2L HYPERNETWORK                                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Text-to-LoRA Hypernetwork Training                                 â”‚   â”‚
â”‚  â”‚ Text descriptions â†’ LoRA weight predictions                        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                  â”‚                                          â”‚
â”‚                                  â–¼                                          â”‚
â”‚  ğŸŒ CLIENT DEPLOYMENT                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ ONNX Runtime + TypeScript Client                                   â”‚   â”‚
â”‚  â”‚ Real-time persona generation in browser                            â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“Š Technical Implementation

### Dataset Processing & Labeling
- **Scale**: 84,653 utterances across five public conversation datasets
- **Personality Framework**: 10 slider-style traits (bipolar dimensions)
- **Augmentation**: Synthetic data generation via GPT-4o rephrasing for trait expression
- **Quality Control**: Automated filtering and manual validation of trait annotations

### LoRA Adapter Training
- **Base Model**: Llama-3 8B
- **Adapters**: 18 trait-specific LoRA modules
- **Training Infrastructure**: Together AI Fine-tuning APIÂ²
- **Optimization**: Task-specific fine-tuning for personality trait expression

### Hypernetwork Architecture
- **Framework**: Text-to-LoRA (T2L) adaptation for style control
- **Input**: Natural language personality descriptions
- **Output**: LoRA weight predictions for real-time adapter generation
- **Innovation**: Style-focused rather than task-focused weight space navigation

### Client Integration
- **Runtime**: ONNX.js for browser-based inference
- **Interface**: TypeScript web client
- **Performance**: Real-time persona adapter generation
- **Deployment**: Lightweight client-side processing

## ğŸ¯ Demonstrated Capabilities

This prototype showcases several key technical and product development competencies:

### Technical Depth
- **Research Translation**: Converting academic T2L hypernetwork concepts into production-ready personality control
- **Multi-Modal Pipeline**: End-to-end system from raw conversation data to web deployment
- **Novel Application**: Extending weight-space linearity from task competence to style/personality domains

### Product Experience
- **User Interface**: Intuitive web-based persona generation and testing
- **Real-Time Processing**: Client-side hypernetwork inference for immediate feedback
- **Scalable Architecture**: Modular design supporting additional personality dimensions

### Engineering Execution
- **Rapid Development**: Complete system built solo over one week (nights/weekends)
- **Infrastructure Integration**: Together AI API integration for scalable training
- **Cross-Platform Deployment**: ONNX model export for web compatibility

## ğŸ“š Dataset Citations

This work builds upon several foundational conversation datasets:

- **EmpatheticDialogues**: Rashkin, H., et al. (2019). "Towards Empathetic Open-domain Conversation Models." *ACL 2019*.
- **DailyDialog**: Li, Y., et al. (2017). "DailyDialog: A Manually Labelled Multi-turn Dialogue Dataset." *IJCNLP 2017*.
- **EmotionLines**: Chen, S. Y., et al. (2018). "EmotionLines: An Emotion Corpus of Multi-Party Conversations." *LREC 2018*.
- **MELD**: Poria, S., et al. (2019). "MELD: A Multimodal Multi-Party Dataset for Emotion Recognition in Conversations." *ACL 2019*.
- **IEMOCAP**: Busso, C., et al. (2008). "IEMOCAP: Interactive Emotional Dyadic Motion Capture Database." *Language Resources and Evaluation*.

## ğŸ”¬ Research Foundation

Â¹ **Text-to-LoRA (T2L)**: *[Detailed citation pending - paper published June 2025]*

The original T2L work demonstrated that hypernetworks could generate task-specific LoRA adapters from textual descriptions, establishing the foundational principle of navigating weight space through natural language conditioning. This project extends that concept from task competence to personality and style control.

## ğŸ› ï¸ Infrastructure & Documentation

Â² **Together AI Integration**: Complete implementation details and API documentation available at [together.ai/docs](https://together.ai/docs)

The training pipeline leverages Together AI's Fine-tuning API for LoRA adapter creation and GPU clusters for hypernetwork training, demonstrating practical integration with modern ML infrastructure.

## ğŸš€ Project Structure

```
lora-web-builder/
â”œâ”€â”€ scripts/                    # Training pipeline
â”‚   â”œâ”€â”€ 01_dataset_creation/   # Data processing & labeling
â”‚   â”œâ”€â”€ 02_lora_training/      # LoRA adapter training
â”‚   â””â”€â”€ 03_hypernetwork_training/ # T2L hypernetwork training
â”œâ”€â”€ data/persona/              # Processed datasets & trait annotations
â”œâ”€â”€ client/                    # TypeScript web interface
â”‚   â”œâ”€â”€ src/                   # React + ONNX.js implementation
â”‚   â””â”€â”€ models/                # ONNX hypernetwork models
â””â”€â”€ README_HYBRID_APPROACH.md  # Detailed technical implementation guide
```

## ğŸ¯ Impact & Applications

This work demonstrates how research advances in hypernetworks can be rapidly translated into practical systems for controllable AI behavior. The lightweight, client-side approach to personality steering opens new possibilities for:

- **Safety & Alignment**: Dynamic personality constraints without model retraining
- **User Experience**: Personalized AI interactions through real-time style adaptation  
- **Edge Deployment**: Minimal computational overhead for persona switching
- **Research Extensions**: Framework for exploring other controllable model behaviors

---

*This project represents a focused technical demonstration built to showcase research translation capabilities, infrastructure integration skills, and rapid prototyping in modern ML stacks.* 